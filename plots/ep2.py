# Updating the plot labels to correct "14b" to "13b" and replacing (a+b+c) with (QTR+STF+VTFIDF)


# Layer numbers for RankLlama 14b
import matplotlib.pyplot as plt
plt.figure(figsize=(16, 6))
# Layer numbers
layers = list(range(32))

# R^2 scores for each combination
abc_scores = [
    0.1404608100642879, 0.3986440352251983, 0.4197314607651287, 0.5960333641417128, 0.7604419586098374, 0.8342409969054225, 
    0.8741204222261623, 0.8940627965935417, 0.9042121483017188, 0.9147030158543574, 0.9186135678593128, 0.9245096025505255, 
    0.9372936046852539, 0.9365954174288108, 0.9324231071781842, 0.9371495511335832, 0.9536251535944604, 0.9589073009149175, 
    0.9576492266671841, 0.9620400998069504, 0.9623894148073986, 0.9645965221988861, 0.9639562304809745, 0.9650646811588013, 
    0.9703454854703398, 0.9708036536955965, 0.9765808608658846, 0.9766332159544695, 0.978075568084277, 0.9803358058231012, 
    0.9820154175135565, 0.9827924158508218
]

abc_squared_scores = [
    0.13215341961069138, 0.37110147754044465, 0.4289278589874319, 0.6162066112865323, 0.7878868311256101, 0.8559810856492605, 
    0.8926995509006685, 0.905724091861306, 0.9118064330200308, 0.9170925772725133, 0.9187213008731364, 0.9247937879999892, 
    0.936160783374925, 0.9334381757288126, 0.932184961730168, 0.9391197297842149, 0.957115521144712, 0.9637521052364663, 
    0.9624523104380902, 0.9661888480545109, 0.96650204545474, 0.9680545537244775, 0.9677478662702522, 0.9685922999760224, 
    0.9735037943158693, 0.9730948406494077, 0.9788105489424006, 0.9783711415047458, 0.9792902942401356, 0.9818329765687532, 
    0.9826698861559352, 0.9833047726398796
]

abc_cubed_scores = [
    0.11832981827489075, 0.3363691630585859, 0.42736355476721677, 0.6210257361636805, 0.8029018062719278, 0.8697509848747771, 
    0.9039888359550962, 0.9121188311787926, 0.9152014479610662, 0.916846750553859, 0.9169476591268308, 0.9243048856222404, 
    0.9342698179289337, 0.929989244094694, 0.931977524325256, 0.9407236890521173, 0.9594882149109359, 0.9669919948268718, 
    0.9656307013831502, 0.9684091773773114, 0.9691561020088121, 0.9702482053549836, 0.9703225955369869, 0.971036296430083, 
    0.9755797487720641, 0.9748195404886157, 0.9802523292700073, 0.9793635670737934, 0.9800781046983637, 0.9828390276043611, 
    0.9830650008074938, 0.9835190079504198
]

BM25_scores = [
    0.0479952463551625, 0.1584958011843709, 0.17531568588763202, 0.2615499168239246, 0.3603514250659011, 0.3942651909088296, 
    0.41873419609120066, 0.43426767405453115, 0.4435133073734927, 0.4426004956451486, 0.4399735841496635, 0.4512277535380582, 
    0.45058961765815697, 0.4648844844480967, 0.45562538920515894, 0.46073001159894456, 0.4781618469140638, 0.47380255352020495, 
    0.4705793815981181, 0.47216674949031423, 0.4817130889140774, 0.49306306627622243, 0.4845486303524924, 0.48675272985177376, 
    0.4942340994290477, 0.4975383303927706, 0.5027046648882589, 0.49678056068188525, 0.4935645510261951, 0.4961630044752199, 
    0.4792561977347052, 0.45326648405533165
]


layers_14b = list(range(40))

# R² scores for RankLlama 14b
abc_scores_14b = [
    0.1960179187126061, 0.3428975293982145, 0.48214726004247366, 0.6841704249911885, 0.7645232442676795, 0.8333359057203238, 
    0.9018249562482608, 0.9125862995693255, 0.9219855682252082, 0.9204039399302457, 0.9307545039285776, 0.9324650973870352, 
    0.9319328819818675, 0.9486468943123135, 0.9510803715397157, 0.9634246463699272, 0.9587337490006338, 0.9565781763456784, 
    0.9624106339743894, 0.9602206342654154, 0.9628965772345583, 0.9679560042635602, 0.9689026428732987, 0.9656154823086123, 
    0.9629335664357582, 0.9639844427884509, 0.9638222844410933, 0.9686234250518879, 0.9651564636104405, 0.967529516918174, 
    0.9702916247865407, 0.9701055859635801, 0.9730705907331401, 0.9739562767730718, 0.9726605842513819, 0.9762857461645598, 
    0.9819225732852552, 0.9831791910187345, 0.987238075963048, 0.9882886304933566
]

abc_squared_scores_14b = [
    0.1923359663319929, 0.3377078696971082, 0.49410728895120637, 0.701464652545895, 0.782289337155244, 0.8446453321407943, 
    0.9079754526986542, 0.9190956114852903, 0.927008817875023, 0.9254216849955231, 0.9338744077720615, 0.934558206860941, 
    0.9326917246227395, 0.949704382670572, 0.9513215844202526, 0.9637218082530263, 0.9594896110560377, 0.9586162635761084, 
    0.9637417536249745, 0.961412174554615, 0.9638333769305143, 0.9695723670120084, 0.9698548527359496, 0.9672427785426096, 
    0.9647423254736629, 0.966081386007374, 0.9662437990809647, 0.9705200304264445, 0.9672054847226165, 0.969538031466163, 
    0.9723539969312059, 0.9721838429565433, 0.975432520552967, 0.9757852859479965, 0.9747202834682782, 0.9773471636138927, 
    0.9830330773304378, 0.9838892200743662, 0.9880892964863741, 0.9890753708860937
]

abc_cubed_scores_14b = [
    0.1822246842392291, 0.32531928875476723, 0.49695078044311936, 0.7106731525037445, 0.7934958705227709, 0.8527073951423156, 
    0.912810050304165, 0.9238982517449794, 0.9301015071668409, 0.9292253864781659, 0.9351965346894525, 0.9351866233873062, 
    0.9315073229458496, 0.9499554244683719, 0.9512538040945157, 0.9634834940659035, 0.9596658831870596, 0.9599801799163421, 
    0.9644804440397017, 0.9621031372812991, 0.9644423046035691, 0.9705695670849253, 0.9702972933304068, 0.9681207775659498, 
    0.9657432609627725, 0.9673037187402408, 0.9675800360941175, 0.9715895834128954, 0.9687516038994108, 0.9709606167007492, 
    0.9736589305599817, 0.9733920954175934, 0.9770302506651987, 0.976990770887513, 0.9761160591661825, 0.978058363811828, 
    0.9837230527397746, 0.9842173687544165, 0.9886137468467746, 0.989685912167846
]

BM25_scores_14b = [
    0.09917468634083515, 0.23406596351801878, 0.32424276053137113, 0.4590007651540461, 0.5227828482283161, 0.5875563409679609, 
    0.6715805439692952, 0.6899257224077431, 0.7027408963213329, 0.7193232136765193, 0.7310392882023552, 0.7345035408719162, 
    0.7362741533908634, 0.7580083522130596, 0.7609676209212415, 0.7875510136130313, 0.7738745627735469, 0.7707095071283224, 
    0.7700583148377583, 0.7670111691455757, 0.7780882407315279, 0.7837108036289491, 0.7880499123256784, 0.7822447420944363, 
    0.7807929733667965, 0.7775232845423594, 0.762591505500391, 0.766081607738377, 0.7589337006639654, 0.7551672316482768, 
    0.7752288728173329, 0.7723802871529775, 0.7730758889580731, 0.763024775374977, 0.7672548488213145, 0.7776015912368073, 
    0.7846752393543751, 0.7841685769714003, 0.7834086033736452, 0.7641890082890946
]

# RankLlama 7b
plt.subplot(2, 1, 1)
plt.plot(layers, abc_scores, marker='o', label='(QTR+STF+VTFIDF)', color='blue')
plt.plot(layers, abc_squared_scores, marker='o', label='(QTR+STF+VTFIDF)^2', color='green')
plt.plot(layers, abc_cubed_scores, marker='o', label='(QTR+STF+VTFIDF)^3', color='cyan')
plt.plot(layers, BM25_scores, marker='o', label='BM25', color='orange')
plt.title('R² Scores Across Layers for RankLlama 7b', fontsize=16)
plt.xlabel('Layer Number', fontsize=14)
plt.ylabel('R² Score', fontsize=14)
plt.legend(loc='best', fontsize=12)
plt.grid(True)

# RankLlama 13b
plt.subplot(2, 1, 2)
plt.plot(layers_14b, abc_scores_14b, marker='o', label='(QTR+STF+VTFIDF)', color='blue')
plt.plot(layers_14b, abc_squared_scores_14b, marker='o', label='(QTR+STF+VTFIDF)^2', color='green')
plt.plot(layers_14b, abc_cubed_scores_14b, marker='o', label='(QTR+STF+VTFIDF)^3', color='cyan')
plt.plot(layers_14b, BM25_scores_14b, marker='o', label='BM25', color='orange')
plt.title('R² Scores Across Layers for RankLlama 13b', fontsize=16)
plt.xlabel('Layer Number', fontsize=14)
plt.ylabel('R² Score', fontsize=14)
plt.legend(loc='best', fontsize=12)
plt.grid(True)

# Adjust layout to reduce height and increase width
plt.tight_layout()
plt.savefig('ep2.png')
